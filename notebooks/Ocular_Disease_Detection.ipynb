{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T23:23:55.102274Z",
     "iopub.status.busy": "2024-09-15T23:23:55.102001Z",
     "iopub.status.idle": "2024-09-15T23:24:16.641428Z",
     "shell.execute_reply": "2024-09-15T23:24:16.640614Z",
     "shell.execute_reply.started": "2024-09-15T23:23:55.102242Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define our example directories and files\n",
    "IMAGE_SIZE = [150, 150]\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   validation_split=0.15,\n",
    "                                   featurewise_center=False,\n",
    "                                   samplewise_center=False,\n",
    "                                   featurewise_std_normalization=False,\n",
    "                                   samplewise_std_normalization=False,\n",
    "                                   zca_whitening=False,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip=False\n",
    "                                  )\n",
    "\n",
    "# Note that the testing data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-for-different-eye-disease/DATASET_101/Train',\n",
    "                                                    target_size = (150, 150),\n",
    "                                                    batch_size = 64,\n",
    "                                                    subset = \"training\",\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    #color_mode = 'grayscale'       # Comment\n",
    "                                                   )\n",
    "\n",
    "# Flow validation images in batches of 32 using train_datagen generator\n",
    "validation_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-for-different-eye-disease/DATASET_101/Train',\n",
    "                                                         target_size = (150, 150),\n",
    "                                                         batch_size = 64,\n",
    "                                                         subset = \"validation\",\n",
    "                                                         class_mode = 'categorical',\n",
    "                                                         #color_mode = 'grayscale'       # Comment\n",
    "                                                        )\n",
    "\n",
    "# Flow testing images in batches of 32 using test_datagen generator\n",
    "test_generator = test_datagen.flow_from_directory('/kaggle/input/dataset-for-different-eye-disease/DATASET_101/Test',\n",
    "                                                  target_size = (150, 150),\n",
    "                                                  batch_size  = 64,\n",
    "                                                  class_mode  = 'categorical',\n",
    "                                                  #color_mode = 'grayscale',       # Comment\n",
    "                                                  shuffle = False\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T23:24:16.643555Z",
     "iopub.status.busy": "2024-09-15T23:24:16.643035Z",
     "iopub.status.idle": "2024-09-15T23:24:17.480575Z",
     "shell.execute_reply": "2024-09-15T23:24:17.479729Z",
     "shell.execute_reply.started": "2024-09-15T23:24:16.643521Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(150, 150, 3), padding=\"same\", name=\"L1\"),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (7,7), activation='relu', name=\"L2\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (7,7), activation='relu', name=\"L3\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    #tf.keras.layers.Conv2D(128, (7,7), activation='relu', name=\"L4\"),\n",
    "    #tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # 256 neuron hidden layer\n",
    "    tf.keras.layers.Dense(256, activation='relu', name=\"dense1\" ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    # 128 neuron hidden layer\n",
    "    tf.keras.layers.Dense(128, activation='relu', name=\"dense2\" ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    # 6 neuron output layer\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T23:24:17.481890Z",
     "iopub.status.busy": "2024-09-15T23:24:17.481583Z",
     "iopub.status.idle": "2024-09-16T00:23:42.638278Z",
     "shell.execute_reply": "2024-09-16T00:23:42.637378Z",
     "shell.execute_reply.started": "2024-09-15T23:24:17.481858Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Compiling the CNN  # Set the training parameters\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy', #keras.metrics.Precision(), keras.metrics.Recall(),\n",
    "                         #keras.metrics.SpecificityAtSensitivity(0.5),\n",
    "                         #keras.metrics.SensitivityAtSpecificity(0.5)\n",
    "                         ])\n",
    "\n",
    "# Training the CNN on the Training set and evaluating it on the Test set\n",
    "# Stop training if loss doesn't keep decreasing.\n",
    "model_es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-11, patience = 8, verbose = 1)\n",
    "model_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 3, verbose = 1)\n",
    "\n",
    "# Automatically saves the best weights of the model, based on best val_accuracy\n",
    "model_mcp = ModelCheckpoint(filepath = 'model_1_CNN.keras', monitor = 'val_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "history = model.fit(train_generator, validation_data = validation_generator,\n",
    "                    epochs = 50, callbacks = [model_es, model_rlr, model_mcp]       # CHANGE number of epochs\n",
    "                    #steps_per_epoch=62, validation_steps=6\n",
    "                    )\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Total Time:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:23:42.640924Z",
     "iopub.status.busy": "2024-09-16T00:23:42.640325Z",
     "iopub.status.idle": "2024-09-16T00:23:42.983460Z",
     "shell.execute_reply": "2024-09-16T00:23:42.982707Z",
     "shell.execute_reply.started": "2024-09-16T00:23:42.640888Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# accuracies\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(history.history['accuracy'], 'r', label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('No. of Iteration (Epochs)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('train_val_acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:23:42.984706Z",
     "iopub.status.busy": "2024-09-16T00:23:42.984412Z",
     "iopub.status.idle": "2024-09-16T00:24:30.187510Z",
     "shell.execute_reply": "2024-09-16T00:24:30.186548Z",
     "shell.execute_reply.started": "2024-09-16T00:23:42.984657Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Generate predictions using the model\n",
    "Y_pred = model.predict(test_generator)  # Assuming test_generator yields batches of data\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Print confusion matrix\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "target_names = ['ACRIMA', 'Glaucoma', 'ODIR-5K', 'ORIGA', 'cataract', 'retina_disease']\n",
    "print('Classification Report')\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:24:30.189081Z",
     "iopub.status.busy": "2024-09-16T00:24:30.188581Z",
     "iopub.status.idle": "2024-09-16T00:26:04.281133Z",
     "shell.execute_reply": "2024-09-16T00:26:04.280337Z",
     "shell.execute_reply.started": "2024-09-16T00:24:30.189047Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "number_of_examples = len(test_generator.filenames)\n",
    "number_of_generator_calls = math.ceil(number_of_examples / (1.0 * 64))\n",
    "# 1.0 above is to skip integer division\n",
    "\n",
    "test_labels = []\n",
    "test_images = []\n",
    "\n",
    "for i in range(0,int(number_of_generator_calls)):\n",
    "    test_labels.extend(np.array(test_generator[i][1]))\n",
    "\n",
    "for i in range(0,int(number_of_generator_calls)):\n",
    "    test_images.extend(np.array(test_generator[i][0]))\n",
    "    %matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "predictions = model.predict(test_generator)\n",
    "new_labels = []\n",
    "for i in range(0,1395):\n",
    "  new_labels.append(np.argmax(predictions[i]))\n",
    "newtest_labels = []\n",
    "for i in range(0,1395):\n",
    "  newtest_labels.append(np.argmax(test_labels[i]))\n",
    "cm = confusion_matrix(y_true=newtest_labels, y_pred=new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:26:04.283199Z",
     "iopub.status.busy": "2024-09-16T00:26:04.282713Z",
     "iopub.status.idle": "2024-09-16T00:26:36.887786Z",
     "shell.execute_reply": "2024-09-16T00:26:36.886776Z",
     "shell.execute_reply.started": "2024-09-16T00:26:04.283148Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "# Calculate accuracy score\n",
    "score = metrics.accuracy_score(newtest_labels, new_labels)\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "# Generate prediction probabilities\n",
    "pred_prob = model.predict(test_generator)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "c = roc_auc_score(newtest_labels, pred_prob, multi_class='ovo')\n",
    "print(\"AUC:\", c)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "lw = 2\n",
    "precision = {}\n",
    "recall = {}\n",
    "\n",
    "for i in range(6):\n",
    "    fpr[i], tpr[i], _ = roc_curve(newtest_labels, pred_prob[:, i], pos_label=i)\n",
    "    precision[i], recall[i], _ = roc_curve(newtest_labels, pred_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"precision vs. recall curve\")\n",
    "plt.savefig('prc.png')\n",
    "plt.show()\n",
    "\n",
    "n_classes = 6\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at these points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally, average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "\n",
    "colors = cycle(['green', 'darkorange', 'cornflowerblue', 'yellow' ])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw, label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "                                                       ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ssr.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2012645,
     "sourceId": 3332017,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
