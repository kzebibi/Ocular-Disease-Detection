{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3332017,"sourceType":"datasetVersion","datasetId":2012645}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define our example directories and files\nIMAGE_SIZE = [150, 150]\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255.,\n                                   validation_split=0.15,\n                                   featurewise_center=False,\n                                   samplewise_center=False,\n                                   featurewise_std_normalization=False,\n                                   samplewise_std_normalization=False,\n                                   zca_whitening=False,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True,\n                                   vertical_flip=False\n                                  )\n\n# Note that the testing data should not be augmented!\ntest_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n\n# Flow training images in batches of 32 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-for-different-eye-disease/DATASET_101/Train',\n                                                    target_size = (150, 150),\n                                                    batch_size = 64,\n                                                    subset = \"training\",\n                                                    class_mode = 'categorical',\n                                                    #color_mode = 'grayscale'       # Comment\n                                                   )\n\n# Flow validation images in batches of 32 using train_datagen generator\nvalidation_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-for-different-eye-disease/DATASET_101/Train',\n                                                         target_size = (150, 150),\n                                                         batch_size = 64,\n                                                         subset = \"validation\",\n                                                         class_mode = 'categorical',\n                                                         #color_mode = 'grayscale'       # Comment\n                                                        )\n\n# Flow testing images in batches of 32 using test_datagen generator\ntest_generator = test_datagen.flow_from_directory('/kaggle/input/dataset-for-different-eye-disease/DATASET_101/Test',\n                                                  target_size = (150, 150),\n                                                  batch_size  = 64,\n                                                  class_mode  = 'categorical',\n                                                  #color_mode = 'grayscale',       # Comment\n                                                  shuffle = False\n                                                 )","metadata":{"execution":{"iopub.status.busy":"2024-09-15T23:23:55.102001Z","iopub.execute_input":"2024-09-15T23:23:55.102274Z","iopub.status.idle":"2024-09-15T23:24:16.641428Z","shell.execute_reply.started":"2024-09-15T23:23:55.102242Z","shell.execute_reply":"2024-09-15T23:24:16.640614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(150, 150, 3), padding=\"same\", name=\"L1\"),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(32, (7,7), activation='relu', name=\"L2\"),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(64, (7,7), activation='relu', name=\"L3\"),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    #tf.keras.layers.Conv2D(128, (7,7), activation='relu', name=\"L4\"),\n    #tf.keras.layers.MaxPooling2D(2,2),\n\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n\n    # 256 neuron hidden layer\n    tf.keras.layers.Dense(256, activation='relu', name=\"dense1\" ),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.25),\n    # 128 neuron hidden layer\n    tf.keras.layers.Dense(128, activation='relu', name=\"dense2\" ),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.25),\n\n    # 6 neuron output layer\n    tf.keras.layers.Dense(6, activation='softmax')\n])\n\n# Print the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-15T23:24:16.643035Z","iopub.execute_input":"2024-09-15T23:24:16.643555Z","iopub.status.idle":"2024-09-15T23:24:17.480575Z","shell.execute_reply.started":"2024-09-15T23:24:16.643521Z","shell.execute_reply":"2024-09-15T23:24:17.479729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nimport time\n\nstart = time.time()\n\n# Compiling the CNN  # Set the training parameters\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n              metrics = ['accuracy', #keras.metrics.Precision(), keras.metrics.Recall(),\n                         #keras.metrics.SpecificityAtSensitivity(0.5),\n                         #keras.metrics.SensitivityAtSpecificity(0.5)\n                         ])\n\n# Training the CNN on the Training set and evaluating it on the Test set\n# Stop training if loss doesn't keep decreasing.\nmodel_es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-11, patience = 8, verbose = 1)\nmodel_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 3, verbose = 1)\n\n# Automatically saves the best weights of the model, based on best val_accuracy\nmodel_mcp = ModelCheckpoint(filepath = 'model_1_CNN.keras', monitor = 'val_accuracy',\n                             save_best_only = True, verbose = 1)\n\nhistory = model.fit(train_generator, validation_data = validation_generator,\n                    epochs = 50, callbacks = [model_es, model_rlr, model_mcp]       # CHANGE number of epochs\n                    #steps_per_epoch=62, validation_steps=6\n                    )\n\nend = time.time()\nelapsed = end - start\nprint(\"Total Time:\", elapsed)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T23:24:17.481583Z","iopub.execute_input":"2024-09-15T23:24:17.481890Z","iopub.status.idle":"2024-09-16T00:23:42.638278Z","shell.execute_reply.started":"2024-09-15T23:24:17.481858Z","shell.execute_reply":"2024-09-16T00:23:42.637378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# accuracies\nplt.figure(figsize=(6,4))\nplt.plot(history.history['accuracy'], 'r', label='Training accuracy')\nplt.plot(history.history['val_accuracy'], 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('No. of Iteration (Epochs)')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\nplt.savefig('train_val_acc.png')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T00:23:42.640325Z","iopub.execute_input":"2024-09-16T00:23:42.640924Z","iopub.status.idle":"2024-09-16T00:23:42.983460Z","shell.execute_reply.started":"2024-09-16T00:23:42.640888Z","shell.execute_reply":"2024-09-16T00:23:42.982707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Generate predictions using the model\nY_pred = model.predict(test_generator)  # Assuming test_generator yields batches of data\ny_pred = np.argmax(Y_pred, axis=1)\n\n# Print confusion matrix\nprint('Confusion Matrix')\nprint(confusion_matrix(test_generator.classes, y_pred))\n\n# Print classification report\ntarget_names = ['ACRIMA', 'Glaucoma', 'ODIR-5K', 'ORIGA', 'cataract', 'retina_disease']\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T00:23:42.984412Z","iopub.execute_input":"2024-09-16T00:23:42.984706Z","iopub.status.idle":"2024-09-16T00:24:30.187510Z","shell.execute_reply.started":"2024-09-16T00:23:42.984657Z","shell.execute_reply":"2024-09-16T00:24:30.186548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nnumber_of_examples = len(test_generator.filenames)\nnumber_of_generator_calls = math.ceil(number_of_examples / (1.0 * 64))\n# 1.0 above is to skip integer division\n\ntest_labels = []\ntest_images = []\n\nfor i in range(0,int(number_of_generator_calls)):\n    test_labels.extend(np.array(test_generator[i][1]))\n\nfor i in range(0,int(number_of_generator_calls)):\n    test_images.extend(np.array(test_generator[i][0]))\n    %matplotlib inline\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\npredictions = model.predict(test_generator)\nnew_labels = []\nfor i in range(0,1395):\n  new_labels.append(np.argmax(predictions[i]))\nnewtest_labels = []\nfor i in range(0,1395):\n  newtest_labels.append(np.argmax(test_labels[i]))\ncm = confusion_matrix(y_true=newtest_labels, y_pred=new_labels)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T00:24:30.188581Z","iopub.execute_input":"2024-09-16T00:24:30.189081Z","iopub.status.idle":"2024-09-16T00:26:04.281133Z","shell.execute_reply.started":"2024-09-16T00:24:30.189047Z","shell.execute_reply":"2024-09-16T00:26:04.280337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\n\n# Calculate accuracy score\nscore = metrics.accuracy_score(newtest_labels, new_labels)\nprint(\"Accuracy score: {}\".format(score))\n\n# Generate prediction probabilities\npred_prob = model.predict(test_generator)\n\n# Calculate ROC AUC score\nc = roc_auc_score(newtest_labels, pred_prob, multi_class='ovo')\nprint(\"AUC:\", c)\n\n# Compute ROC curve and ROC area for each class\nfpr = {}\ntpr = {}\nroc_auc = {}\nlw = 2\nprecision = {}\nrecall = {}\n\nfor i in range(6):\n    fpr[i], tpr[i], _ = roc_curve(newtest_labels, pred_prob[:, i], pos_label=i)\n    precision[i], recall[i], _ = roc_curve(newtest_labels, pred_prob[:, i], pos_label=i)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n\nplt.xlabel(\"recall\")\nplt.ylabel(\"precision\")\nplt.legend(loc=\"best\")\nplt.title(\"precision vs. recall curve\")\nplt.savefig('prc.png')\nplt.show()\n\nn_classes = 6\n\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at these points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\n# Finally, average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\n\ncolors = cycle(['green', 'darkorange', 'cornflowerblue', 'yellow' ])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw, label='ROC curve of class {0} (area = {1:0.4f})'\n                                                       ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.savefig('ssr.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T00:26:04.282713Z","iopub.execute_input":"2024-09-16T00:26:04.283199Z","iopub.status.idle":"2024-09-16T00:26:36.887786Z","shell.execute_reply.started":"2024-09-16T00:26:04.283148Z","shell.execute_reply":"2024-09-16T00:26:36.886776Z"},"trusted":true},"execution_count":null,"outputs":[]}]}